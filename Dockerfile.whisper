## Dockerfile для локального Whisper.cpp API сервера
## Используется для транскрибации голосовых сообщений
## Whisper.cpp provides 2-4x better performance than openai-whisper

FROM python:3.11-slim

WORKDIR /app

# Install system dependencies including build tools for whisper.cpp
RUN apt-get update && apt-get install -y \
    ffmpeg \
    git \
    build-essential \
    cmake \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies for Whisper.cpp
RUN pip install --no-cache-dir \
    pywhispercpp \
    fastapi \
    uvicorn[standard] \
    python-multipart

# Copy Whisper.cpp API server script
COPY whisper_server.py .

# Models will be auto-downloaded on first use to /root/.cache/whisper.cpp/
# Available models: tiny, base, small, medium, large

# Expose port for API
EXPOSE 8000

# Default environment variables
ENV WHISPER_MODEL=base \
    WHISPER_THREADS=4 \
    PYTHONUNBUFFERED=1

# Healthcheck
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/health')"

# Запуск FastAPI сервера
CMD ["uvicorn", "whisper_server:app", "--host", "0.0.0.0", "--port", "8000"]


